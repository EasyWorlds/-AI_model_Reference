{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "0tUeLEvHPdY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5a4b70-ea9b-4ad8-dcb3-ec250329a025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive"
      ],
      "metadata": {
        "id": "wvT27fDwPepe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6db09b-d72d-4f2a-c5fb-ec395f77bf8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64Aa9i2_PdAX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "resize dataset pixel size"
      ],
      "metadata": {
        "id": "9kACLGBZRiNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# 입력 경로에서 모든 이미지 파일을 가져오기\n",
        "for i in range(3,0,-1):\n",
        "\n",
        "#    1~13, 25\n",
        "\n",
        "  print(i)\n",
        "\n",
        "  image_file = \"/content/gdrive/MyDrive/aircon/test/2/muni\"+str(i)+\".jpg\"\n",
        "  image = Image.open(image_file)\n",
        "\n",
        "  # 이미지 크기 조절\n",
        "  resized_image = image.resize((224,224))\n",
        "\n",
        "  # 새로운 경로에 이미지 저장\n",
        "  resized_image.save(image_file)\n",
        "\n",
        "#tower는 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u93QyRWHO0a8",
        "outputId": "d86e7749-5838-47ea-b517-6b5ce8c89153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "2\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그냥 이미지 원본들을 데이터셋으로 만들기"
      ],
      "metadata": {
        "id": "4qazjF_v609F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = os.listdir(root_dir)\n",
        "\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "\n",
        "        for i, class_name in enumerate(self.classes):\n",
        "            class_path = os.path.join(root_dir, class_name)\n",
        "            for file_name in os.listdir(class_path):\n",
        "                self.data.append(os.path.join(class_path, file_name))\n",
        "                self.labels.append(i)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return {'data': img, 'label': label}\n"
      ],
      "metadata": {
        "id": "1zkHc_cPjHbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 모든 이미지를 동일한 크기로 조정\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "pBucFFE7Petu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(\"/content/gdrive/MyDrive/AIR/aug\", transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "5hafE1LSPR4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(\"/content/gdrive/MyDrive/AIR/test\", transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "Jd4ZG8fFsdG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader.dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqn4AHJQ-14S",
        "outputId": "aac11591-f7ed-4856-8ca1-80b962b31e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 aug"
      ],
      "metadata": {
        "id": "0LFyiIUtSNrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python Augmentor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbV9sWo0iW_F",
        "outputId": "126d3b80-3e15-42ac-f5d1-bfb0d5086a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Collecting Augmentor\n",
            "  Downloading Augmentor-0.2.12-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (9.4.0)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (4.66.1)\n",
            "Installing collected packages: Augmentor\n",
            "Successfully installed Augmentor-0.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from Augmentor import Pipeline\n",
        "\n",
        "def apply_augmentation(input_path, output_path):\n",
        "    # Input path에 있는 모든 이미지 파일 가져오기\n",
        "    image_files = [f for f in os.listdir(input_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    # Augmentor 파이프라인 생성\n",
        "    pipeline = Pipeline(input_path, output_directory=output_path)\n",
        "\n",
        "    # 필요한 augmentation 작업 추가 (회전, 뒤집기, 밝기 조절, 색상 변환 등)\n",
        "    pipeline.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    pipeline.flip_left_right(probability=0.5)\n",
        "    pipeline.random_brightness(probability=0.7, min_factor=0.7, max_factor=1.3)\n",
        "    pipeline.random_color(probability=0.5, min_factor=0.7, max_factor=1.3)\n",
        "\n",
        "    # Augmentation 적용 및 저장\n",
        "    pipeline.sample(len(image_files), multi_threaded=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 경로 1 및 경로 2 지정\n",
        "    input_path = \"/content/gdrive/MyDrive/AIR/train/2\"\n",
        "    output_path = \"/content/gdrive/MyDrive/AIR/aug/2\"\n",
        "\n",
        "    # Augmentation 적용 및 저장\n",
        "    apply_augmentation(input_path, output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7qZwqdihHvR",
        "outputId": "3bb3a1ea-9fd0-4e65-9ea1-e063d1daac4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 30 image(s) found.\n",
            "Output directory set to /content/gdrive/MyDrive/AIR/aug/2."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=224x224 at 0x79DF42D0D480>: 100%|██████████| 30/30 [00:00<00:00, 124.57 Samples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 준비 및 학습"
      ],
      "metadata": {
        "id": "HAjbo5rz69rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'{device} is available')"
      ],
      "metadata": {
        "id": "WJ2pI5N8Pev_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e855fd-b3c2-40ae-c1a9-690c45b88852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(128, 3)  # Assuming there are 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "\n",
        "        # Reshape before fully connected layers\n",
        "        x = x.view(-1, 32 * 56 * 56)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "oeQErNl3S9Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CL3CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CL3CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 256)\n",
        "        self.relu4 = nn.ReLU()  # Corrected the name here\n",
        "\n",
        "        self.fc2 = nn.Linear(256, 3)  # Assuming there are 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.pool3(self.relu3(self.conv3(x)))\n",
        "\n",
        "        # Reshape before fully connected layers\n",
        "        x = x.view(-1, 64 * 28 * 28)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.relu4(self.fc1(x))  # Corrected the name here\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "UgmyObSzs7VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CL3FC3CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CL3FC3CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 256)\n",
        "        self.relu4 = nn.ReLU()  # Corrected the name here\n",
        "        self.fc2=nn.Linear(256,64)\n",
        "        self.relu5=nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 3)  # Assuming there are 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.pool3(self.relu3(self.conv3(x)))\n",
        "\n",
        "        # Reshape before fully connected layers\n",
        "        x = x.view(-1, 64 * 28 * 28)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.relu4(self.fc1(x))  # Corrected the name here\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu5(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "DPMRzdo9yKan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CL4CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CL4CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 14 * 14, 256)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 3)  # Assuming there are 3 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.pool3(self.relu3(self.conv3(x)))\n",
        "        x = self.pool4(self.relu4(self.conv4(x)))\n",
        "\n",
        "        # Reshape before fully connected layers\n",
        "        x = x.view(-1, 128 * 14 * 14)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.relu5(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "gdOVEwkZ3UBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CL5CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CL5CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(256 * 7 * 7, 256)  # Corrected the name here\n",
        "        self.relu6 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 3)  # Assuming there are 3 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.pool3(self.relu3(self.conv3(x)))\n",
        "        x = self.pool4(self.relu4(self.conv4(x)))\n",
        "        x = self.pool5(self.relu5(self.conv5(x)))  # Corrected the name here\n",
        "\n",
        "        # Reshape before fully connected layers\n",
        "        x = x.view(-1, 256 * 7 * 7)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.relu6(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "4DcNdYnw5HMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CL4FC3CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CL4FC3CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 14 * 14, 256)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.relu6=nn.ReLU()\n",
        "        self.fc3=nn.Linear(64,3)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.pool3(self.relu3(self.conv3(x)))\n",
        "        x = self.pool4(self.relu4(self.conv4(x)))\n",
        "\n",
        "        # Reshape before fully connected layers\n",
        "        x = x.view(-1, 128 * 14 * 14)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.relu5(self.fc1(x))\n",
        "        x=self.relu6(self.fc2(x))\n",
        "        x=self.fc3(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "BPMjjtSipnMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 인스턴스 생성\n",
        "model = CL4FC3CNN()\n",
        "#CL3CNN\n",
        "#CL3FC3CNN\n",
        "#CL4CNN\n",
        "#CL5CNN"
      ],
      "metadata": {
        "id": "MgdLjxdmwXeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "zbb_ZPpVPe0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10"
      ],
      "metadata": {
        "id": "FY0rwed1o7o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()  # 학습 모드로 설정\n",
        "\n",
        "\n",
        "    for batch in train_loader:\n",
        "        data, labels = batch['data'], batch['label']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # 각 에폭 끝에 손실 출력 또는 로깅 추가\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "    #  모델 성능 평가\n",
        "    model.eval()  # 평가 모드로 설정\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            data, labels = batch['data'], batch['label']\n",
        "\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'{epoch+1} epoch - Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "id": "B4Nw5g82Tjm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda68938-c5cc-49ff-ffa4-c8cbe13713a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.693561851978302\n",
            "1 epoch - Test Accuracy: 40.00%\n",
            "Epoch [2/10], Loss: 0.5382905602455139\n",
            "2 epoch - Test Accuracy: 20.00%\n",
            "Epoch [3/10], Loss: 1.098335862159729\n",
            "3 epoch - Test Accuracy: 30.00%\n",
            "Epoch [4/10], Loss: 0.04717760160565376\n",
            "4 epoch - Test Accuracy: 20.00%\n",
            "Epoch [5/10], Loss: 0.014002463780343533\n",
            "5 epoch - Test Accuracy: 20.00%\n",
            "Epoch [6/10], Loss: 1.807303786277771\n",
            "6 epoch - Test Accuracy: 30.00%\n",
            "Epoch [7/10], Loss: 0.003925358410924673\n",
            "7 epoch - Test Accuracy: 20.00%\n",
            "Epoch [8/10], Loss: 0.9944594502449036\n",
            "8 epoch - Test Accuracy: 0.00%\n",
            "Epoch [9/10], Loss: 0.40150535106658936\n",
            "9 epoch - Test Accuracy: 40.00%\n",
            "Epoch [10/10], Loss: 0.010020076297223568\n",
            "10 epoch - Test Accuracy: 40.00%\n"
          ]
        }
      ]
    }
  ]
}